{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiyopure/streamlit-llm-app/blob/main/%E3%80%90%E4%B8%AD%E9%96%93%E8%AA%B2%E9%A1%8C_%E8%A7%A3%E7%AD%94%E7%94%A8%E3%80%91%E6%9C%AC%E6%A0%BC%E7%9A%84%E3%81%AARAG_AI%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E3%81%AE%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E9%96%8B%E7%99%BA%E3%81%AB%E3%83%88%E3%83%A9%E3%82%A4%E3%81%97%E3%82%88%E3%81%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D0eN-VfXZxw"
      },
      "source": [
        "# 【中間課題: 解答用】本格的なRAG/AIエージェントのシステム開発にトライしよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WRaC4-PSG8s"
      },
      "source": [
        "## 事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R4cDODLAcnn"
      },
      "source": [
        "### 【1. OpenAI APIキーの設定】"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DjVb-RqaDzz"
      },
      "source": [
        "シークレット機能でOpenAI APIのAPIキーを設定しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJVHxyg-3V98"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvQPic3PUy7v"
      },
      "source": [
        "### 【2. 必要なライブラリのインストール】"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkUfjYv4U6_W"
      },
      "source": [
        "コース共通"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k75K-Kt6XBLe",
        "outputId": "049ef1d9-b9c3-4c25-db93-ec7f2d5f653b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain==0.3.26\n",
            "  Using cached langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting openai==1.91.0\n",
            "  Using cached openai-1.91.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting langchain-community==0.3.26\n",
            "  Using cached langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (6.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==1.91.0) (4.15.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.26) (1.26.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx==0.28.1) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.26) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain==0.3.26) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain==0.3.26) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.26) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.26) (3.2.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.66->langchain==0.3.26) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.26) (1.1.0)\n",
            "Using cached langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "Using cached openai-1.91.0-py3-none-any.whl (735 kB)\n",
            "Using cached langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "Installing collected packages: openai, langchain, langchain-community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.3.31\n",
            "    Uninstalling langchain-community-0.3.31:\n",
            "      Successfully uninstalled langchain-community-0.3.31\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.35 requires openai<3.0.0,>=1.104.2, but you have openai 1.91.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.26 langchain-community-0.3.26 openai-1.91.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.26 openai==1.91.0 langchain-community==0.3.26 httpx==0.28.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3f1BBIUU9xe"
      },
      "source": [
        "中間課題用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uT24MofCBliv",
        "outputId": "5fd16c38-44bf-4b12-ac7d-4616b18c4dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-docx==1.2.0 in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: docx2txt==0.9 in /usr/local/lib/python3.12/dist-packages (0.9)\n",
            "Collecting chromadb==1.0.13\n",
            "  Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting tiktoken==0.9.0\n",
            "  Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx==1.2.0) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx==1.2.0) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (2.11.10)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.13) (4.25.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken==0.9.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken==0.9.0) (2.32.5)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.0.13) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.0.13) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.13) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.13) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.13) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.13) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.0.13) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.13) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.13) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.13) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.13) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.13) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.13) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.13) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.13) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.13) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb==1.0.13) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.13) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.13) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.13) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==1.0.13) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog>=2.4.0->chromadb==1.0.13) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog>=2.4.0->chromadb==1.0.13) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.13) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.13) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.13) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken==0.9.0) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.0.13) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.0.13) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb==1.0.13) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.0.13) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.0.13) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.13) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.13) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.13) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.13) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.13) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.13) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.13) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.0.13) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.0.13) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb==1.0.13) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.0.13) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.0.13) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.0.13) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.13) (0.6.1)\n",
            "Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, chromadb\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-chroma 0.1.4 requires chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0, but you have chromadb 1.0.13 which is incompatible.\n",
            "langchain-openai 0.3.35 requires openai<3.0.0,>=1.104.2, but you have openai 1.91.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-1.0.13 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx==1.2.0 docx2txt==0.9 chromadb==1.0.13 tiktoken==0.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsXxt8vyVA4E"
      },
      "source": [
        "### 【3. Googleドライブとの接続（マウント）】"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "collapsed": true,
        "id": "p3PSZUCt70TA",
        "outputId": "19cdaee8-8616-4722-ace7-18780c6cf929"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO_segxAVYFK"
      },
      "source": [
        "### 【4. 外部参照先である「オンラインMTG議事録」フォルダのパス設定】"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQXOtr8VVYlC"
      },
      "outputs": [],
      "source": [
        "dir_path = \"/content/drive/MyDrive/オンラインMTG議事録\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lV5SC0Lmy0o"
      },
      "source": [
        "## 【中間課題①】オンラインMTG議事録を外部参照するRAGシステムの開発"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-L7he36ZWwh"
      },
      "source": [
        "### リセット処理（動作検証用）\n",
        "\n",
        "「データベース化済み」フォルダと「.db」フォルダ内のファイルを全て削除する処理\n",
        "\n",
        "**<font color= \"red\">※余裕がある方は、まずは自力での実装にトライしてみてください</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C20-1Cb7MjDY"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def clear_complete_dir(dir_path):\n",
        "    print(dir_path)\n",
        "    if os.path.isdir(dir_path):\n",
        "        if dir_path.split(\"/\")[-1] == \".db\":\n",
        "            shutil.rmtree(dir_path)\n",
        "            os.mkdir(dir_path)\n",
        "            print(f\"作成済みの全てのベクターストアを削除しました。\")\n",
        "            return\n",
        "\n",
        "    if os.path.isdir(dir_path):\n",
        "        files = os.listdir(dir_path)\n",
        "        if dir_path.split(\"/\")[-1] == \"データベース化済み\":\n",
        "            for file in files:\n",
        "                os.remove(os.path.join(dir_path, file))\n",
        "            print(f\"対象テーマの「データベース化済み」フォルダを空にしました: {dir_path}\")\n",
        "            return\n",
        "        for file in files:\n",
        "            clear_complete_dir(os.path.join(dir_path, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "18iibBUxTdjq"
      },
      "outputs": [],
      "source": [
        "# リセット処理の実行\n",
        "clear_complete_dir(dir_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSDI-7isaScz"
      },
      "source": [
        "### ヒント"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngNn1_TvqSBc"
      },
      "source": [
        "#### ヒント①（気軽に開いてOK）\n",
        "\n",
        "RAGの外部参照先である「オンラインMTG議事録」フォルダ内の各テーマフォルダ内で、「データベース化前」フォルダ内にはあるが「データベース化済み」フォルダ内にはない議事録ファイルを読み込み、また「データベース化済み」フォルダ内にファイルをコピーする処理\n",
        "\n",
        "**<font color= \"red\">※階層の深いフォルダ内のファイルを全て取得するためには、「再起処理」と呼ばれる少し複雑なコードを書く必要があります。  \n",
        "実装イメージが湧く方、もしくは腕試しをしたい方は、自力での実装にトライしてみてください</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z51VT3JM-LK1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def recursive_file_check(path, theme_docs):\n",
        "    # 受け取ったパスがフォルダかどうかで条件分岐\n",
        "    if os.path.isdir(path):\n",
        "        # 「データベース化済み」もしくは「.db」フォルダの場合はファイル読み込みの処理が不要であるため、後続の処理をストップ\n",
        "        if path.split(\"/\")[-1] == \"データベース化済み\" or path.split(\"/\")[-1] == \".db\":\n",
        "            return\n",
        "        # フォルダ内のファイル/フォルダ名の一覧を取得\n",
        "        files = os.listdir(path)\n",
        "        # 一覧をループ処理\n",
        "        for file in files:\n",
        "            # フォルダ内のファイルもしくはフォルダのパスを渡し、再度関数を呼び出す（関数の中で同じ関数を呼び出す「再帰処理」）\n",
        "            recursive_file_check(os.path.join(path, file), theme_docs)\n",
        "    else:\n",
        "        # 受け取ったパスがファイルの場合のみ、「読み込み」と「コピー」の処理を実行\n",
        "        file_load(path, theme_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDJQE_l3-LNL"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "\n",
        "def file_load(path, theme_docs):\n",
        "    # パスを「/」で分割してリスト作成\n",
        "    splitted_path = path.split(\"/\")\n",
        "    # パスからテーマ名を取り出し\n",
        "    dir_path = \"/content/drive/MyDrive/オンラインMTG議事録\"\n",
        "    theme_name = \"\"\n",
        "    for path_elem in splitted_path:\n",
        "        if path_elem in os.listdir(dir_path):\n",
        "            theme_name = path_elem\n",
        "            break\n",
        "    # 「データベース化前」フォルダ内のファイルのパスであるため、「2つ階層を上げたところまでのパス」と「データベース化済み/ファイル名」のパスを連結\n",
        "    save_filename = os.path.join(\"/\".join(path.split(\"/\")[:-2]), f\"データベース化済み/{os.path.basename(path)}\")\n",
        "    # 「データベース化前」フォルダ内にはあるが「データベース化済み」フォルダ内にはない議事録ファイルの場合\n",
        "    if not os.path.isfile(save_filename):\n",
        "        # 拡張子「.docx」のファイルを読み込み\n",
        "        loader = Docx2txtLoader(path)\n",
        "        doc = loader.load()\n",
        "        # 議事録ファイルを「データベース化済み」フォルダ内に保存\n",
        "        new_doc = Document()\n",
        "        new_doc.add_paragraph(doc[0].page_content)\n",
        "        new_doc.save(save_filename)\n",
        "        # テーマ名をキー、取得したドキュメントを値として辞書に追加\n",
        "        if theme_name in theme_docs:\n",
        "            theme_docs[theme_name] += doc\n",
        "        else:\n",
        "            theme_docs[theme_name] = doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toKict1j-LPu"
      },
      "outputs": [],
      "source": [
        "# 辞書「theme_docs」に、各テーマ名をキーとしてドキュメント一覧を格納する\n",
        "theme_docs = {}\n",
        "# 「オンラインMTG議事録」フォルダ内のファイル読み込みと「データベース化済み」フォルダへのコピーの処理を実行\n",
        "recursive_file_check(dir_path, theme_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QJgG7VsSQU6_"
      },
      "outputs": [],
      "source": [
        "# 辞書の中身を確認\n",
        "theme_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de6cA6MYqYg7"
      },
      "source": [
        "#### ヒント②（基本開かない）\n",
        "\n",
        "ベクターストア作成の事前準備\n",
        "\n",
        "```Markdown\n",
        "- CharacterTextSplitterクラスのインスタンスを作成　（※Lesson13: Chapter3: 「Document transformers」を参照）\n",
        "- OpenAIEmbeddingsクラスのインスタンスを作成　（※Lesson13: Chapter3: 「Text embedding models」を参照）\n",
        "- 7つのテーマ名一覧（「営業」など）が格納されたリストを作成\n",
        "```\n",
        "\n",
        "**<font color= \"red\">※上記ロジックを参照し、まずは自力での実装にトライしてみてください</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vff269u72xA"
      },
      "source": [
        "##### 上記ロジックのコード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQsKcEnpk6_"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# CharacterTextSplitterクラスのインスタンスを作成\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "# OpenAIEmbeddingsクラスのインスタンスを作成\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJwSswpJpmgd"
      },
      "outputs": [],
      "source": [
        "# 7つのテーマ名一覧（「営業」など）が格納されたリストを作成\n",
        "theme_list = []\n",
        "for filename in os.listdir(dir_path):\n",
        "    if not filename.startswith('.'):\n",
        "        theme_list.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGCNIDge-_5x"
      },
      "outputs": [],
      "source": [
        "# リストの中身を確認\n",
        "theme_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVTholKCqbK9"
      },
      "source": [
        "#### ヒント③（最後の手段）\n",
        "\n",
        "ベクターストアの作成と、すでに存在する場合は読み込んでデータを追加する処理\n",
        "\n",
        "```Markdown\n",
        "- 対象のベクターストアの種類\n",
        "  - 全テーマ横断のベクターストア「.all_chromadb」\n",
        "  - 各テーマごとのベクターストア「.テーマ名_chromadb」\n",
        "```\n",
        "\n",
        "**<font color= \"red\">※こちらのヒントには、中間課題を解くための最も重要なロジックとコードが書かれています。  \n",
        "できる限り最後まで参照せず、トライしてみてください。</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bsUroiMrk5c"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1lj4hpiq3Vp"
      },
      "outputs": [],
      "source": [
        "# テーマ名をキー、Retrieverを値として追加する用の空の辞書を用意\n",
        "theme_retriever = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SSBvQ0V2FJI"
      },
      "source": [
        "テーマ名（「営業」など）の一覧が格納されたリストに対してfor文を回し、  \n",
        "新たにベクターストアに追加するデータが該当テーマにおいて存在する場合のみ、for文の中で以下のロジックを実装する。\n",
        "\n",
        "```Markdown\n",
        "- 「オンラインMTG議事録」フォルダから読み込んだデータの中で、テーマ名に該当するデータを取り出し、チャンク分割を行う　（※Lesson13: Chapter3: 「Document transformers」を参照）\n",
        "- テーマに対応するベクターストアが「.db」フォルダ内に存在するかどうかで条件分岐\n",
        "  - 存在する場合\n",
        "    - 該当テーマのベクターストアを読み込む　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "    - 該当テーマのベクターストアにチャンク分割したドキュメントを追加する　（※自力での調査が必要）\n",
        "    - 全テーマ横断のベクターストアを読み込む　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "    - 全テーマ横断のベクターストアにチャンク分割したドキュメントを追加する　（※自力での調査が必要）\n",
        "  - 存在しない場合\n",
        "    - チャンク分割したドキュメントを使い、該当テーマのベクターストアを作成　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "    - 全テーマ横断のベクターストアが「.db」フォルダ内に存在するかどうかで条件分岐\n",
        "      - 存在する場合\n",
        "        - 全テーマ横断のベクターストアを読み込む　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "        - 全テーマ横断のベクターストアにチャンク分割したドキュメントを追加する　（※自力での調査が必要）\n",
        "      - 存在しない場合\n",
        "        - チャンク分割したドキュメントを使い、全テーマ横断のベクターストアを作成　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "- ベクターストアからRetrieverを作成し、テーマ名をキー、Retrieverを値として辞書に追加\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1IH48aLNIM2"
      },
      "source": [
        "最終的に作成される辞書「theme_retriever」のデータ構造\n",
        "\n",
        "```Markdown\n",
        "{\n",
        "    '全社': 「.全社_chromadb」のRetriever,\n",
        "    '教育': 「.教育_chromadb」のRetriever,\n",
        "    'マーケティング': 「.マーケティング_chromadb」のRetriever,\n",
        "    '営業': 「.営業_chromadb」のRetriever,\n",
        "    '採用': 「.採用_chromadb」のRetriever,\n",
        "    '開発': 「.開発_chromadb」のRetriever,\n",
        "    '顧客': 「.顧客_chromadb」のRetriever\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NDt8QzW2xt0"
      },
      "source": [
        "##### 上記ロジックのコード\n",
        "**<font color= \"red\">※まずは上記のロジックをもとに、解答にトライしてみてください。  \n",
        "ただし多くの試行錯誤を行ったがどうしても実装できず、想定学習時間を大幅に超過した場合のみ、  \n",
        "最後の手段として上記ロジックの解答例の以下コードを参照してください。</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fnFSsIkGt3z"
      },
      "outputs": [],
      "source": [
        "# テーマ名（「営業」など）の一覧が格納されたリストに対してfor文を回す\n",
        "for theme_name in theme_list:\n",
        "    # 新たにベクターストアに追加するデータが該当テーマにおいて存在する場合のみ、ベクターストアの作成やデータ追加の処理を実行\n",
        "    if theme_name in theme_docs:\n",
        "        # 「オンラインMTG議事録」フォルダから読み込んだデータの中で、テーマ名に該当するデータを取り出し、チャンク分割を行う\n",
        "        splitted_docs = text_splitter.split_documents(theme_docs[theme_name])\n",
        "        # テーマに対応するベクターストアが「.db」フォルダ内に存在するかどうかで条件分岐\n",
        "        if os.path.isdir(f\"{dir_path}/.db/.{theme_name}_chromadb\"):\n",
        "            # 該当テーマのベクターストアを読み込む\n",
        "            db = Chroma(persist_directory=f\"{dir_path}/.db/.{theme_name}_chromadb\", embedding_function=embeddings)\n",
        "            # 該当テーマのベクターストアにチャンク分割したドキュメントを追加する\n",
        "            db.add_documents(documents=splitted_docs)\n",
        "            # 全テーマ横断のベクターストアを読み込む\n",
        "            all_db = Chroma(persist_directory=f\"{dir_path}/.db/.all_chromadb\", embedding_function=embeddings)\n",
        "            # 全テーマ横断のベクターストアにチャンク分割したドキュメントを追加する\n",
        "            all_db.add_documents(documents=splitted_docs)\n",
        "        else:\n",
        "            # チャンク分割したドキュメントを使い、該当テーマのベクターストアを作成\n",
        "            db = Chroma.from_documents(splitted_docs, embeddings, persist_directory=f\"{dir_path}/.db/.{theme_name}_chromadb\")\n",
        "            # 全テーマ横断のベクターストアが「.db」フォルダ内に存在するかどうかで条件分岐\n",
        "            if os.path.isdir(f\"{dir_path}/.db/.all_chromadb\"):\n",
        "                # 全テーマ横断のベクターストアを読み込む\n",
        "                all_db = Chroma(persist_directory=f\"{dir_path}/.db/.all_chromadb\", embedding_function=embeddings)\n",
        "                # 全テーマ横断のベクターストアにチャンク分割したドキュメントを追加する\n",
        "                all_db.add_documents(documents=splitted_docs)\n",
        "            else:\n",
        "                # チャンク分割したドキュメントを使い、全テーマ横断のベクターストアを作成\n",
        "                all_db = Chroma.from_documents(splitted_docs, embeddings, persist_directory=f\"{dir_path}/.db/.all_chromadb\")\n",
        "\n",
        "        # ベクターストアからRetrieverを作成し、テーマ名をキー、Retrieverを値として辞書に追加\n",
        "        theme_retriever[theme_name] = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV-bUjS1qbTC"
      },
      "outputs": [],
      "source": [
        "# テーマ名をキー、Retrieverを値として追加した辞書の中身を確認\n",
        "theme_retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dk-FricD_gj"
      },
      "source": [
        "#### ヒント④（ヒント①〜③の続きのコードがどうしても書けない場合に開く）\n",
        "\n",
        "ヒント①〜③の続きで、LLMに回答を生成させるまでのロジック\n",
        "\n",
        "**<font color= \"red\">※こちらのヒントには、ヒント①〜③の続きでLLMに回答を生成させるまでのロジックが書かれています。  \n",
        "ここまで全てヒントを開くと「ほぼ中間課題の解答例」となります。  \n",
        "そのためヒント①〜③を開いた場合、このヒントはできる限り最後まで開かずにトライしてみてください。</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dP9OG-ucolI"
      },
      "source": [
        "##### LLMに回答を生成させるまでのロジック"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vu2ap6SFY1Z"
      },
      "source": [
        "```Markdown\n",
        "- 全テーマ横断のベクターストア「.all_chromadb」を読み込む　（※Lesson13: Chapter3: 「Vector Stores」を参照）\n",
        "- Retrieverを作成する　（※Lesson13: Chapter3: 「Retrievers」を参照）\n",
        "- ChatOpenAIクラスのインスタンスを、ストリーミング出力のオプション付きで作成する　（※Lesson15: Chapter2: 「各イベントのカスタム方法」を参照）\n",
        "- 会話履歴の記憶機能が搭載されたRAGのChainを作成する　（※Lesson13: Chapter4を参照）\n",
        "- 会話履歴を格納するための空のリストを用意する\n",
        "- ユーザー入力値を変数に格納する\n",
        "- ユーザー入力値と会話履歴をもとに回答を生成する　（※Lesson13: Chapter4を参照）\n",
        "- 会話履歴のリストにユーザー入力値とLLMからの回答を追加する　（※Lesson13: Chapter4を参照）\n",
        "- 再度ユーザー入力値をLLMに与え、会話履歴の記憶機能が搭載されていることを確認する\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJc-vu0PIZSe"
      },
      "source": [
        "### 解答"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1145985"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain langchain-core langchain-openai chromadb python-docx docx2txt tiktoken openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85d8522b"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.17 langchain-core==0.1.48 langchain-openai==0.1.17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb4cdf9d"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.17 langchain-core==0.1.45 langchain-openai==0.1.17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02cc7aec"
      },
      "outputs": [],
      "source": [
        "!pip install pydantic==1.10.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e563e8e"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-openai==0.1.17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0097e97f"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NQK7PDcA6y1"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-openai langchain-community langchain-text-splitters chromadb python-docx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD8HJZydA6y2"
      },
      "outputs": [],
      "source": [
        "!pip install -q tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80a97270"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.26 openai==1.91.0 langchain-community==0.3.26 httpx==0.28.1 chromadb python-docx docx2txt tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29807954"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y langchain langchain-openai langchain-community langchain-text-splitters chromadb python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f92d67b"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.17 langchain-openai==0.1.17 langchain-community==0.0.32 langchain-text-splitters==0.0.1 chromadb python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bcab475"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y langchain langchain-openai langchain-community langchain-text-splitters chromadb python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "905137e1"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-openai langchain-community langchain-text-splitters chromadb python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d9aa432"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-openai langchain-community langchain-text-splitters chromadb python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-mbB83VA7BS"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtbwDjW3A7Yv",
        "outputId": "be7784d9-dcd5-40af-d41b-b8ecfac7f49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: openai 1.109.1\n",
            "Uninstalling openai-1.109.1:\n",
            "  Successfully uninstalled openai-1.109.1\n",
            "Found existing installation: langchain 0.3.27\n",
            "Uninstalling langchain-0.3.27:\n",
            "  Successfully uninstalled langchain-0.3.27\n",
            "Found existing installation: langchain-core 0.3.79\n",
            "Uninstalling langchain-core-0.3.79:\n",
            "  Successfully uninstalled langchain-core-0.3.79\n",
            "Found existing installation: langchain-openai 0.3.35\n",
            "Uninstalling langchain-openai-0.3.35:\n",
            "  Successfully uninstalled langchain-openai-0.3.35\n",
            "Found existing installation: langchain-community 0.3.31\n",
            "Uninstalling langchain-community-0.3.31:\n",
            "  Successfully uninstalled langchain-community-0.3.31\n",
            "Found existing installation: langchain-chroma 0.1.4\n",
            "Uninstalling langchain-chroma-0.1.4:\n",
            "  Successfully uninstalled langchain-chroma-0.1.4\n",
            "Found existing installation: chromadb 0.5.23\n",
            "Uninstalling chromadb-0.5.23:\n",
            "  Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\n",
            "langgraph-prebuilt 1.0.2 requires langchain-core>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m🚀 RAGシステム起動中...\n",
            "\n",
            "📁 再作成: /content/drive/MyDrive/オンラインMTG議事録/データベース化済み\n",
            "🗑️ 削除: /content/drive/MyDrive/オンラインMTG議事録/.db\n",
            "📁 再作成: /content/drive/MyDrive/オンラインMTG議事録/.db\n",
            "✅ リセット完了\n",
            "\n",
            "🆕 コピー＆読み込み: 採用.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/採用/データベース化前/採用.docx\n",
            "🆕 コピー＆読み込み: マーケティング.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/マーケティング/データベース化前/マーケティング.docx\n",
            "🆕 コピー＆読み込み: 営業.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/営業/データベース化前/営業.docx\n",
            "🆕 コピー＆読み込み: 全社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/全社/データベース化前/全社.docx\n",
            "🆕 コピー＆読み込み: クリスタルワークス株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/既存/クリスタルワークス株式会社/データベース化前/クリスタルワークス株式会社.docx\n",
            "🆕 コピー＆読み込み: ピクセルパルス株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/既存/ピクセルパルス株式会社/データベース化前/ピクセルパルス株式会社.docx\n",
            "🆕 コピー＆読み込み: グローバルフュージョン株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/既存/グローバルフュージョン株式会社/データベース化前/グローバルフュージョン株式会社.docx\n",
            "🆕 コピー＆読み込み: ブルースカイ・マーケティング株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/既存/ブルースカイ・マーケティング株式会社/データベース化前/ブルースカイ・マーケティング株式会社.docx\n",
            "🆕 コピー＆読み込み: バーチャルビジョン合同会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/既存/バーチャルビジョン合同会社/データベース化前/バーチャルビジョン合同会社.docx\n",
            "🆕 コピー＆読み込み: フォーカスゲート株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/見込み/フォーカスゲート株式会社/データベース化前/フォーカスゲート株式会社.docx\n",
            "🆕 コピー＆読み込み: トランスミッション・グループ株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/見込み/トランスミッション・グループ株式会社/データベース化前/トランスミッション・グループ株式会社.docx\n",
            "🆕 コピー＆読み込み: デジテック・ホライズン株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/顧客/見込み/デジテック・ホライズン株式会社/データベース化前/デジテック・ホライズン株式会社.docx\n",
            "🆕 コピー＆読み込み: 開発.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/開発/データベース化前/開発.docx\n",
            "🆕 コピー＆読み込み: 教育.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/教育/データベース化前/教育.docx\n",
            "🆕 コピー＆読み込み: 採用.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/採用/データベース化前/採用.docx\n",
            "🆕 コピー＆読み込み: マーケティング.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/マーケティング/データベース化前/マーケティング.docx\n",
            "🆕 コピー＆読み込み: 営業.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/営業/データベース化前/営業.docx\n",
            "🆕 コピー＆読み込み: 全社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/全社/データベース化前/全社.docx\n",
            "🆕 コピー＆読み込み: クリスタルワークス株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/既存/クリスタルワークス株式会社/データベース化前/クリスタルワークス株式会社.docx\n",
            "🆕 コピー＆読み込み: ピクセルパルス株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/既存/ピクセルパルス株式会社/データベース化前/ピクセルパルス株式会社.docx\n",
            "🆕 コピー＆読み込み: グローバルフュージョン株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/既存/グローバルフュージョン株式会社/データベース化前/グローバルフュージョン株式会社.docx\n",
            "🆕 コピー＆読み込み: ブルースカイ・マーケティング株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/既存/ブルースカイ・マーケティング株式会社/データベース化前/ブルースカイ・マーケティング株式会社.docx\n",
            "🆕 コピー＆読み込み: バーチャルビジョン合同会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/既存/バーチャルビジョン合同会社/データベース化前/バーチャルビジョン合同会社.docx\n",
            "🆕 コピー＆読み込み: フォーカスゲート株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/見込み/フォーカスゲート株式会社/データベース化前/フォーカスゲート株式会社.docx\n",
            "🆕 コピー＆読み込み: トランスミッション・グループ株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/見込み/トランスミッション・グループ株式会社/データベース化前/トランスミッション・グループ株式会社.docx\n",
            "🆕 コピー＆読み込み: デジテック・ホライズン株式会社.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/顧客/見込み/デジテック・ホライズン株式会社/データベース化前/デジテック・ホライズン株式会社.docx\n",
            "🆕 コピー＆読み込み: 開発.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/開発/データベース化前/開発.docx\n",
            "🆕 コピー＆読み込み: 教育.docx → /content/drive/MyDrive/オンラインMTG議事録/データベース化済み/データベース化済み/教育/データベース化前/教育.docx\n",
            "\n",
            "📂 テーマ読み込み完了: ['採用', 'マーケティング', '営業', '全社', '顧客', '開発', '教育', 'データベース化済み']\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "テーマ処理中: 100%|██████████| 8/8 [00:24<00:00,  3.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌐 全テーマ横断ベクターストア更新完了\n",
            "\n",
            "🤖 回答: 前者の文脈では、佐藤優がWebサイト経由でのリード数を増加させるための戦略について話し合う場を設けています。彼は目的を再確認し、具体的な施策とその効果測定について議論を進めようとしています。中村花と田中健も目的の確認に賛成し、施策の具体化や過去のデータを参考にすることの重要性を強調しています。\n",
            "\n",
            "後者の文脈では、田中翔が新しいプロジェクトの進捗報告と今後の展開について話し合う場を設けています。彼はユーザーからのフィードバックをもとに改善案を考えており、特にユーザーエクスペリエンスの向上に焦点を当てています。佐藤美咲と鈴木健もフィードバックを共有し、具体的な改善点について意見を出し合っています。\n",
            "\n",
            "このように、前者はリード数の増加に向けた戦略の策定に関する議論であり、後者はプロジェクトの進捗と改善点に関する意見交換が行われています。\n",
            "\n",
            "🤖 回答: ミーティングの中で、どのような取り組みや意見が出されましたか？また、参加者たちはどのように業績の向上に貢献しようとしていますか？\n",
            "\n",
            "🤖 回答: 採用に関するミーティングでは、営業部門の人材ニーズを把握し、効果的な採用戦略を具体化することが目的とされています。現在の採用状況として、営業部門では3名の新卒採用を目指しており、先月の説明会には多くの学生が参加したものの、エントリーシートの提出状況が低く、現在のところエントリーが2名という課題があります。\n",
            "\n",
            "田中由美さんは、学生が興味を持つためには魅力的なコンテンツが必要で、会社の雰囲気や業務内容をわかりやすく伝えることが重要だと指摘しています。松本亮さんは、具体的な業務内容や成長機会を伝えること、インターンシップや実習の機会を充実させることが学生の興味を引くために有効だと提案しています。\n",
            "\n",
            "このように、採用活動においては学生に実際の業務を体験してもらうことが効果的であり、インターンシッププログラムの充実が今後の課題として挙げられています。\n",
            "\n",
            "🤖 回答: プログラムの現状について、各担当者が報告した内容をまとめると以下のようになります。\n",
            "\n",
            "1. **新入社員向け教育プログラム（佐藤和也）**:\n",
            "   - 初回の研修が終了し、参加者からのフィードバックは好評。\n",
            "   - ただし、実践的な部分にもっと時間を割いてほしいという意見があった。\n",
            "\n",
            "2. **リーダーシップ研修（中村美咲）**:\n",
            "   - 中堅社員向けに実施中で、参加者から非常に良い反応を得ている。\n",
            "   - 研修後のフォローアップが不十分との声があり、改善が必要。\n",
            "\n",
            "3. **テクニカルスキル向上プログラム（田中亮）**:\n",
            "   - プログラミングに関するワークショップを開催しており、参加者の反応は良好。\n",
            "   - しかし、実施頻度が低いとの意見があり、定期的に開催できるよう工夫が必要。\n",
            "\n",
            "全体として、各プログラムは進行中であり、参加者からのフィードバックを基に改善点が見つかっていることが確認されました。具体的には、実践的な内容の充実、フォローアップの強化、テクニカルスキル向上の頻度を上げることが今後の課題として挙げられています。\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# セクション1: ライブラリ & API設定\n",
        "# ==============================\n",
        "!pip uninstall -y openai langchain langchain-core langchain-openai langchain-community langchain-chroma chromadb\n",
        "!pip install -q \"openai>=1.104.2,<2.0.0\"\n",
        "!pip install -q \"langchain==0.3.*\" \"langchain-openai==0.3.*\" \"langchain-community==0.3.*\" \\\n",
        "                 \"langchain-chroma==0.1.*\" \"chromadb==0.5.*\" \"tiktoken\" \"docx2txt\" tqdm\n",
        "\n",
        "import os, shutil\n",
        "from tqdm import tqdm\n",
        "from docx import Document\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\").strip()\n",
        "\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# ==============================\n",
        "# セクション2: 初期設定パス\n",
        "# ==============================\n",
        "dir_path = \"/content/drive/MyDrive/オンラインMTG議事録\"\n",
        "db_path = os.path.join(dir_path, \".db\")\n",
        "done_path = os.path.join(dir_path, \"データベース化済み\")\n",
        "os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "# ==============================\n",
        "# セクション3: フォルダリセット関数\n",
        "# ==============================\n",
        "def reset_folders():\n",
        "    for path in [done_path, db_path]:\n",
        "        if os.path.exists(path):\n",
        "            shutil.rmtree(path)\n",
        "            print(f\"🗑️ 削除: {path}\")\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        print(f\"📁 再作成: {path}\")\n",
        "    print(\"✅ リセット完了\\n\")\n",
        "\n",
        "# ==============================\n",
        "# セクション4: docx探索・読み込み\n",
        "# ==============================\n",
        "def recursive_file_check(path, theme_docs):\n",
        "    if os.path.isdir(path):\n",
        "        if os.path.basename(path) in [\"データベース化済み\", \".db\"]:\n",
        "            return\n",
        "        for f in os.listdir(path):\n",
        "            recursive_file_check(os.path.join(path, f), theme_docs)\n",
        "    else:\n",
        "        file_load(path, theme_docs)\n",
        "\n",
        "def file_load(path, theme_docs):\n",
        "    if not path.endswith(\".docx\"):\n",
        "        return\n",
        "    theme_name = None\n",
        "    for elem in path.split(\"/\"):\n",
        "        if elem in os.listdir(dir_path):\n",
        "            theme_name = elem\n",
        "            break\n",
        "    save_filename = os.path.join(done_path, os.path.relpath(path, dir_path))\n",
        "    os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "    if not os.path.isfile(save_filename):\n",
        "        loader = Docx2txtLoader(path)\n",
        "        doc = loader.load()\n",
        "        new_doc = Document()\n",
        "        new_doc.add_paragraph(doc[0].page_content)\n",
        "        new_doc.save(save_filename)\n",
        "        theme_docs.setdefault(theme_name or \"未分類\", []).extend(doc)\n",
        "        print(f\"🆕 コピー＆読み込み: {os.path.basename(path)} → {save_filename}\")\n",
        "    else:\n",
        "        print(f\"⏭️ スキップ: {os.path.basename(path)}（既に処理済み）\")\n",
        "\n",
        "# ==============================\n",
        "# セクション5: ベクターストア構築\n",
        "# ==============================\n",
        "def build_vectorstores(theme_docs):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "    all_db_path = os.path.join(db_path, \".all_chromadb\")\n",
        "    all_docs = []\n",
        "\n",
        "    for theme_name, docs in tqdm(theme_docs.items(), desc=\"テーマ処理中\"):\n",
        "        split_docs = splitter.split_documents(docs)\n",
        "        theme_db_path = os.path.join(db_path, f\".{theme_name}_chromadb\")\n",
        "        if os.path.isdir(theme_db_path):\n",
        "            db = Chroma(persist_directory=theme_db_path, embedding_function=embeddings)\n",
        "            db.add_documents(split_docs)\n",
        "        else:\n",
        "            db = Chroma.from_documents(split_docs, embeddings, persist_directory=theme_db_path)\n",
        "        all_docs.extend(split_docs)\n",
        "\n",
        "    if all_docs:\n",
        "        if os.path.isdir(all_db_path):\n",
        "            db = Chroma(persist_directory=all_db_path, embedding_function=embeddings)\n",
        "            db.add_documents(all_docs)\n",
        "        else:\n",
        "            db = Chroma.from_documents(all_docs, embeddings, persist_directory=all_db_path)\n",
        "        print(\"\\n🌐 全テーマ横断ベクターストア更新完了\")\n",
        "        return db.as_retriever()\n",
        "    else:\n",
        "        print(\"⚠️ docx ファイルが見つかりません。ベクターストアは作成されません。\")\n",
        "        return None\n",
        "\n",
        "# ==============================\n",
        "# セクション6: 会話履歴付きRAGチャット\n",
        "# ==============================\n",
        "def chat_loop(retriever):\n",
        "    if retriever is None:\n",
        "        print(\"⚠️ retriever が存在しないため質問に回答できません。\")\n",
        "        return\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"以下の文脈を参考に質問に答えてください。\\n\\n{context}\\n\\n質問: {input}\"\n",
        "    )\n",
        "    combine_chain = create_stuff_documents_chain(llm, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, combine_chain)\n",
        "\n",
        "    conversation_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\n💬 あなた: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"チャットを終了します。\")\n",
        "            break\n",
        "\n",
        "        response = qa_chain.invoke({\"input\": user_input})\n",
        "        answer = response[\"answer\"]\n",
        "        print(f\"\\n🤖 回答: {answer}\")\n",
        "\n",
        "        conversation_history.append({\"user\": user_input, \"bot\": answer})\n",
        "\n",
        "# ==============================\n",
        "# セクション7: 実行フロー\n",
        "# ==============================\n",
        "def main():\n",
        "    print(\"🚀 RAGシステム起動中...\\n\")\n",
        "    reset_folders()\n",
        "    theme_docs = {}\n",
        "    recursive_file_check(dir_path, theme_docs)\n",
        "    print(f\"\\n📂 テーマ読み込み完了: {list(theme_docs.keys())}\\n\")\n",
        "    retriever = build_vectorstores(theme_docs)\n",
        "    if retriever is None:\n",
        "        print(\"RAG システムを実行できません。docx ファイルを確認してください。\")\n",
        "        return\n",
        "    chat_loop(retriever)\n",
        "\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfuzXDNwA7Yw",
        "outputId": "60cc32af-13ca-4136-ddbc-1aea1b26908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning mount point: /content/drive\n",
            "Mount point cleaned: /content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Check if the mount point exists and is not empty, then clean it up\n",
        "mount_point = '/content/drive'\n",
        "if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
        "    if os.listdir(mount_point):\n",
        "        print(f\"Cleaning mount point: {mount_point}\")\n",
        "        try:\n",
        "            shutil.rmtree(mount_point)\n",
        "            os.makedirs(mount_point)\n",
        "            print(f\"Mount point cleaned: {mount_point}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error cleaning mount point: {e}\")\n",
        "            # Depending on the error, you might want to stop or try mounting anyway\n",
        "            pass # Or raise e if you want to stop on cleanup failure\n",
        "\n",
        "# Attempt to mount Google Drive\n",
        "try:\n",
        "    drive.mount(mount_point)\n",
        "except ValueError as e:\n",
        "    print(f\"Mounting failed: {e}\")\n",
        "    print(\"Please check if the mount point is in use or if there are persistent issues.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during mounting: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBm_dybcA8R6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLw_wv29A8R6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfBVJCSeA8eN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc0Ba1cWA8eO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37whSre9A8pt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuksTmX8A8pu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjmZlJU8A801"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiGnDOpyA801"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTn3e8K7A9Am"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xHyh_0CA9Am"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGVkO2nvj2L"
      },
      "source": [
        "## 【中間課題②】作成したRAGシステムにAIエージェント機能を搭載する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFpCOfzvqE5"
      },
      "source": [
        "### 解答"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1kX5aKEvj8g",
        "outputId": "a3f4d205-8ac6-46dd-9d99-f04127de7099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "作成したツール: ['営業_tool', 'マーケティング_tool', '採用_tool', '開発_tool', '教育_tool', '全社_tool', '顧客_tool', '全テーマ_tool']\n",
            "\n",
            "🚀 エージェントチャット開始（終了するには 'exit' / 'quit' を入力）\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mマーケティング戦略に基づく採用計画についての具体的なアクションプランを知りたいので、まずはマーケティングに関する情報を取得する必要があります。  \n",
            "Action: マーケティング_tool  \n",
            "Action Input: マーケティング戦略に基づく採用計画の具体的なアクションプラン  \u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m[参照テーマ: マーケティング]\n",
            "マーケティング戦略に基づく採用計画の具体的なアクションプランを策定するためには、以下のステップを考慮することが重要です。\n",
            "\n",
            "### 1. ターゲット層の特定\n",
            "- **求める人材のプロファイル作成**: 必要なスキル、経験、価値観を明確にし、どのような人材が企業文化に合うかを定義します。\n",
            "- **ターゲット層の理解**: 若手人材、中堅層、シニア層など、どの層をターゲットにするかを決定します。\n",
            "\n",
            "### 2. 採用チャネルの選定\n",
            "- **SNSの活用**: InstagramやLinkedInなど、ターゲット層に合ったSNSを選び、求人情報や企業文化を発信します。\n",
            "- **求人サイトの利用**: 業界特化型の求人サイトや、一般的な求人サイトを活用して広く募集を行います。\n",
            "\n",
            "### 3. コンテンツマーケティングの実施\n",
            "- **企業の魅力を伝えるコンテンツ作成**: 社員インタビューや職場の雰囲気を伝える動画、ブログ記事を作成し、WebサイトやSNSで発信します。\n",
            "- **成功事例の共有**: 過去の採用成功事例や、社員の成長ストーリーを紹介することで、求職者の興味を引きます。\n",
            "\n",
            "### 4. インフルエンサーやブランドアンバサダーの活用\n",
            "- **業界のインフルエンサーとの連携**: 影響力のある人物に企業の魅力を伝えてもらい、リーチを拡大します。\n",
            "- **社員をブランドアンバサダーに**: 社員が自らのSNSで企業の魅力を発信することで、リアルな声を届けます。\n",
            "\n",
            "### 5. 採用プロセスの最適化\n",
            "- **選考フローの見直し**: 応募から内定までのプロセスをスムーズにし、候補者にとってストレスの少ない体験を提供します。\n",
            "- **フィードバックの実施**: 候補者からのフィードバックを受け取り、採用プロセスの改善に活かします。\n",
            "\n",
            "### 6. 効果測定と改善\n",
            "- **KPIの設定**: 採用活動の効果を測定するための指標（応募数、内定率、採用後の定着率など）を設定します。\n",
            "- **定期的なレビュー**: 採用活動の進捗を定期的にレビューし、必要に応じて戦略を見直します。\n",
            "\n",
            "### 7. 次回のミーティングに向けた準備\n",
            "- **アクションプランの整理**: 各施策の担当者を決定し、実施時期を設定します。\n",
            "- **進捗管理の体制構築**: 各施策の進捗を管理するための体制を整え、次回のミーティングで確認できるようにします。\n",
            "\n",
            "このアクションプランを基に、具体的な施策を持ち寄り、次回のミーティングで詳細を詰めていくことが重要です。\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mこの情報をもとに、マーケティング戦略に基づく採用計画の具体的なアクションプランが明確になりました。  \n",
            "Final Answer: マーケティング戦略に基づく採用計画の具体的なアクションプランは以下の通りです：\n",
            "\n",
            "1. **ターゲット層の特定**\n",
            "   - 求める人材のプロファイル作成\n",
            "   - ターゲット層の理解\n",
            "\n",
            "2. **採用チャネルの選定**\n",
            "   - SNSの活用\n",
            "   - 求人サイトの利用\n",
            "\n",
            "3. **コンテンツマーケティングの実施**\n",
            "   - 企業の魅力を伝えるコンテンツ作成\n",
            "   - 成功事例の共有\n",
            "\n",
            "4. **インフルエンサーやブランドアンバサダーの活用**\n",
            "   - 業界のインフルエンサーとの連携\n",
            "   - 社員をブランドアンバサダーに\n",
            "\n",
            "5. **採用プロセスの最適化**\n",
            "   - 選考フローの見直し\n",
            "   - フィードバックの実施\n",
            "\n",
            "6. **効果測定と改善**\n",
            "   - KPIの設定\n",
            "   - 定期的なレビュー\n",
            "\n",
            "7. **次回のミーティングに向けた準備**\n",
            "   - アクションプランの整理\n",
            "   - 進捗管理の体制構築\n",
            "\n",
            "このアクションプランを基に、具体的な施策を持ち寄り、次回のミーティングで詳細を詰めていくことが重要です。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "🤖 回答:\n",
            "マーケティング戦略に基づく採用計画の具体的なアクションプランは以下の通りです：\n",
            "\n",
            "1. **ターゲット層の特定**\n",
            "   - 求める人材のプロファイル作成\n",
            "   - ターゲット層の理解\n",
            "\n",
            "2. **採用チャネルの選定**\n",
            "   - SNSの活用\n",
            "   - 求人サイトの利用\n",
            "\n",
            "3. **コンテンツマーケティングの実施**\n",
            "   - 企業の魅力を伝えるコンテンツ作成\n",
            "   - 成功事例の共有\n",
            "\n",
            "4. **インフルエンサーやブランドアンバサダーの活用**\n",
            "   - 業界のインフルエンサーとの連携\n",
            "   - 社員をブランドアンバサダーに\n",
            "\n",
            "5. **採用プロセスの最適化**\n",
            "   - 選考フローの見直し\n",
            "   - フィードバックの実施\n",
            "\n",
            "6. **効果測定と改善**\n",
            "   - KPIの設定\n",
            "   - 定期的なレビュー\n",
            "\n",
            "7. **次回のミーティングに向けた準備**\n",
            "   - アクションプランの整理\n",
            "   - 進捗管理の体制構築\n",
            "\n",
            "このアクションプランを基に、具体的な施策を持ち寄り、次回のミーティングで詳細を詰めていくことが重要です。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#必要なライブラリインストール\n",
        "!pip install -q \"langchain==0.3.*\" \"langchain-community==0.3.*\" \"langchain-openai==0.3.*\" \\\n",
        "                \"langchain-chroma==0.1.*\" \"chromadb==0.5.*\" \"tiktoken\" \"docx2txt\" tqdm\n",
        "#OpenAIのカギ（APIキー）を読み込み\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\").strip()\n",
        "\n",
        "\n",
        "# 必要ライブラリ\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "import os, json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 会議メモのフォルダの場所を設定\n",
        "dir_path = \"/content/drive/MyDrive/オンラインMTG議事録\"\n",
        "db_path = os.path.join(dir_path, \".db\")\n",
        "\n",
        "# テーマ一覧\n",
        "THEMES = [\"営業\", \"マーケティング\", \"採用\", \"開発\", \"教育\", \"全社\", \"顧客\"]\n",
        "\n",
        "# 共通の LLM / embeddings作成\n",
        "embeddings = OpenAIEmbeddings()\n",
        "llm_for_chains = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# テーマ別のデータを読み込む関数\n",
        "def load_retriever_for_theme(theme_name):\n",
        "    theme_db_dir = os.path.join(db_path, f\".{theme_name}_chromadb\")\n",
        "    if os.path.isdir(theme_db_dir):\n",
        "        db = Chroma(persist_directory=theme_db_dir, embedding_function=embeddings)\n",
        "        return db.as_retriever()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "#テーマごとのQAチェーン\n",
        "def make_qa_chain_and_answer(retriever, query, model_name=\"gpt-4o-mini\"):\n",
        "    llm = ChatOpenAI(model_name=model_name, temperature=0)\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"以下の文脈を参考に質問に答えてください。\\n\\n{context}\\n\\n質問: {input}\"\n",
        "    )\n",
        "    combine_chain = create_stuff_documents_chain(llm, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, combine_chain)\n",
        "    response = qa_chain.invoke({\"input\": query})\n",
        "    answer = response.get(\"answer\") or response.get(\"output_text\") or str(response)\n",
        "    return answer\n",
        "\n",
        "\n",
        "tools = []\n",
        "\n",
        "# テーマごとのツール作成\n",
        "for theme in THEMES:\n",
        "    retriever = load_retriever_for_theme(theme)\n",
        "    if retriever is None:\n",
        "        # 存在しない場合は無視するが、ツールは作らない。代わりにログ出力。\n",
        "        print(f\"⚠️ テーマ DB が見つかりません: {theme} -> Skipped\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    def make_tool_fn(theme_name, retr):\n",
        "        def tool_fn(query: str):\n",
        "            \"\"\"\n",
        "            この関数はエージェントから呼ばれます。\n",
        "            query を受け、該当テーマのベクターストアのみ参照して回答を生成して返します。\n",
        "            \"\"\"\n",
        "            try:\n",
        "                answer = make_qa_chain_and_answer(retr, query)\n",
        "                return f\"[参照テーマ: {theme_name}]\\n{answer}\"\n",
        "            except Exception as e:\n",
        "                return f\"ツール実行中にエラーが発生しました: {e}\"\n",
        "        return tool_fn\n",
        "\n",
        "    tool = Tool(\n",
        "        name=f\"{theme}_tool\",\n",
        "        func=make_tool_fn(theme, retriever),\n",
        "        description=f\"質問が「{theme}」に関する内容の場合に使ってください。内部的に '{theme}' のベクターストアのみを参照して回答を返します。\"\n",
        "    )\n",
        "    tools.append(tool)\n",
        "\n",
        "#全テーマを横断するツールを作る\n",
        "all_retriever_dir = os.path.join(db_path, \".all_chromadb\")\n",
        "if os.path.isdir(all_retriever_dir):\n",
        "    db_all = Chroma(persist_directory=all_retriever_dir, embedding_function=embeddings)\n",
        "    all_retriever = db_all.as_retriever()\n",
        "\n",
        "    def all_tool_fn(query: str):\n",
        "        try:\n",
        "            return \"[参照テーマ: 全テーマ]\\n\" + make_qa_chain_and_answer(all_retriever, query)\n",
        "        except Exception as e:\n",
        "            return f\"全テーマツール実行中にエラー: {e}\"\n",
        "\n",
        "    tools.append(\n",
        "        Tool(\n",
        "            name=\"全テーマ_tool\",\n",
        "            func=all_tool_fn,\n",
        "            description=\"特定テーマでない、もしくは横断検索したい場合に用いるツール。全データベース（.all_chromadb）を参照します。\"\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "    print(\"⚠️ 全テーマ用 .all_chromadb が見つかりません（フォールバックツールは未作成）\")\n",
        "\n",
        "print(\"作成したツール:\", [t.name for t in tools])\n",
        "\n",
        "\n",
        "# ツールを使いこなすエージェントを作成\n",
        "agent_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    agent_llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# チャットループ（エージェントに入力を投げる）\n",
        "\n",
        "def agent_chat_loop():\n",
        "    print(\"\\n🚀 エージェントチャット開始（終了するには 'exit' / 'quit' を入力）\")\n",
        "    conversation_history = []\n",
        "    while True:\n",
        "        user_input = input(\"\\n💬 あなた: \").strip()\n",
        "        if not user_input:\n",
        "            continue\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"チャットを終了します。\")\n",
        "            break\n",
        "\n",
        "        # エージェントに user_input を渡す（内部でツールを選択して実行）\n",
        "        try:\n",
        "            result = agent.run(user_input)\n",
        "        except Exception as e:\n",
        "            result = f\"エージェント実行中に例外が発生しました: {e}\"\n",
        "\n",
        "        print(f\"\\n🤖 回答:\\n{result}\\n\")\n",
        "        conversation_history.append({\"user\": user_input, \"bot\": result})\n",
        "\n",
        "# 実行\n",
        "agent_chat_loop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpsPIhq_vtbJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnV7zfBvvtlG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ilRvLlvtvA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0-L7he36ZWwh",
        "ngNn1_TvqSBc",
        "de6cA6MYqYg7",
        "QVTholKCqbK9",
        "2NDt8QzW2xt0",
        "6dk-FricD_gj"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}